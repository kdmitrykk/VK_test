{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Скачиваем содержимое"
      ],
      "metadata": {
        "id": "PXEIpuPlsAwy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sj-xNTC470dJ",
        "outputId": "93696288-8a5e-430b-a01b-501cfe887152"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-06-17 14:21:39--  https://downloader.disk.yandex.ru/disk/dff87f6a62bb920049499ac51c6a5e682e9612a6dc6bd02ffe1da396354f67ad/6851b233/hHsHnWApe_ASqMVFpLHBF6_9rCBsLrgaKF5kp2qzYrG5Krh0oqrxe_ldyi5jK0idd-DFUHk89N_oBbBMveda1Q%3D%3D?uid=0&filename=data_test_short.zip&disposition=attachment&hash=FV0wyZboC5sTTzIXVZUjNUU6JbhMopjOAzsTOHYCp9K70U839gY2PzXs50Xtwkjqq/J6bpmRyOJonT3VoXnDag%3D%3D%3A&limit=0&content_type=application%2Fzip&owner_uid=176861886&fsize=12895585234&hid=bd7c4ac68533d5552604210731df433a&media_type=compressed&tknv=v3\n",
            "Resolving downloader.disk.yandex.ru (downloader.disk.yandex.ru)... 77.88.21.127, 2a02:6b8::2:127\n",
            "Connecting to downloader.disk.yandex.ru (downloader.disk.yandex.ru)|77.88.21.127|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://s18klg.storage.yandex.net/rdisk/dff87f6a62bb920049499ac51c6a5e682e9612a6dc6bd02ffe1da396354f67ad/6851b233/hHsHnWApe_ASqMVFpLHBF6_9rCBsLrgaKF5kp2qzYrG5Krh0oqrxe_ldyi5jK0idd-DFUHk89N_oBbBMveda1Q==?uid=0&filename=data_test_short.zip&disposition=attachment&hash=FV0wyZboC5sTTzIXVZUjNUU6JbhMopjOAzsTOHYCp9K70U839gY2PzXs50Xtwkjqq/J6bpmRyOJonT3VoXnDag%3D%3D%3A&limit=0&content_type=application%2Fzip&owner_uid=176861886&fsize=12895585234&hid=bd7c4ac68533d5552604210731df433a&media_type=compressed&tknv=v3&ts=637c8955ab2c0&s=05cf9d3df7e15d8b2a191d0b485a07afcbc5521b0afefa90183da2477350fcb7&pb=U2FsdGVkX18PISkFk-P1DpiVN5n2ZHBeNg6VIT6bLiFhJieWfJRl-NPD8xOHs8f1jGgcdCwkdQ7LaUb0XCdkQ3ywMCoF57UVyXfjg7fw-sY [following]\n",
            "--2025-06-17 14:21:40--  https://s18klg.storage.yandex.net/rdisk/dff87f6a62bb920049499ac51c6a5e682e9612a6dc6bd02ffe1da396354f67ad/6851b233/hHsHnWApe_ASqMVFpLHBF6_9rCBsLrgaKF5kp2qzYrG5Krh0oqrxe_ldyi5jK0idd-DFUHk89N_oBbBMveda1Q==?uid=0&filename=data_test_short.zip&disposition=attachment&hash=FV0wyZboC5sTTzIXVZUjNUU6JbhMopjOAzsTOHYCp9K70U839gY2PzXs50Xtwkjqq/J6bpmRyOJonT3VoXnDag%3D%3D%3A&limit=0&content_type=application%2Fzip&owner_uid=176861886&fsize=12895585234&hid=bd7c4ac68533d5552604210731df433a&media_type=compressed&tknv=v3&ts=637c8955ab2c0&s=05cf9d3df7e15d8b2a191d0b485a07afcbc5521b0afefa90183da2477350fcb7&pb=U2FsdGVkX18PISkFk-P1DpiVN5n2ZHBeNg6VIT6bLiFhJieWfJRl-NPD8xOHs8f1jGgcdCwkdQ7LaUb0XCdkQ3ywMCoF57UVyXfjg7fw-sY\n",
            "Resolving s18klg.storage.yandex.net (s18klg.storage.yandex.net)... 5.255.221.18, 2a02:6b8:c41:d3:0:41af:17a1:aa4d\n",
            "Connecting to s18klg.storage.yandex.net (s18klg.storage.yandex.net)|5.255.221.18|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 12895585234 (12G) [application/zip]\n",
            "Saving to: ‘dataset.zip’\n",
            "\n",
            "dataset.zip         100%[===================>]  12.01G  13.0MB/s    in 9m 45s  \n",
            "\n",
            "2025-06-17 14:31:26 (21.0 MB/s) - ‘dataset.zip’ saved [12895585234/12895585234]\n",
            "\n",
            "Archive:  dataset.zip\n",
            "   creating: data_test_short/\n",
            "   creating: data_test_short/-220020068_456249220/\n",
            "  inflating: data_test_short/-220020068_456249220/-220020068_456249220.mp4  \n",
            "   creating: data_test_short/-220020068_456249373/\n",
            "  inflating: data_test_short/-220020068_456249373/-220020068_456249373.mp4  \n",
            "   creating: data_test_short/-220020068_456249231/\n",
            "  inflating: data_test_short/-220020068_456249231/-220020068_456249231.mp4  \n",
            "   creating: data_test_short/-220020068_456255339/\n",
            "  inflating: data_test_short/-220020068_456255339/-220020068_456255339.mp4  \n",
            "   creating: data_test_short/-220020068_456249284/\n",
            "  inflating: data_test_short/-220020068_456249284/-220020068_456249284.mp4  \n",
            "   creating: data_test_short/-220020068_456241671/\n",
            "  inflating: data_test_short/-220020068_456241671/-220020068_456241671.mp4  \n",
            "   creating: data_test_short/-220020068_456249192/\n",
            "  inflating: data_test_short/-220020068_456249192/-220020068_456249192.mp4  \n",
            "   creating: data_test_short/-220020068_456249257/\n",
            "  inflating: data_test_short/-220020068_456249257/-220020068_456249257.mp4  \n",
            "   creating: data_test_short/-220020068_456249375/\n",
            "  inflating: data_test_short/-220020068_456249375/-220020068_456249375.mp4  \n",
            "   creating: data_test_short/-220020068_456256475/\n",
            "  inflating: data_test_short/-220020068_456256475/-220020068_456256475.mp4  \n",
            "   creating: data_test_short/-220020068_456249206/\n",
            "  inflating: data_test_short/-220020068_456249206/-220020068_456249206.mp4  \n",
            "   creating: data_test_short/-220020068_456249376/\n",
            "  inflating: data_test_short/-220020068_456249376/-220020068_456249376.mp4  \n",
            "   creating: data_test_short/-220020068_456241758/\n",
            "  inflating: data_test_short/-220020068_456241758/-220020068_456241758.mp4  \n",
            "   creating: data_test_short/-220020068_456249243/\n",
            "  inflating: data_test_short/-220020068_456249243/-220020068_456249243.mp4  \n",
            "   creating: data_test_short/-220020068_456249344/\n",
            "  inflating: data_test_short/-220020068_456249344/-220020068_456249344.mp4  \n",
            "   creating: data_test_short/-220020068_456249716/\n",
            "  inflating: data_test_short/-220020068_456249716/-220020068_456249716.mp4  \n",
            "   creating: data_test_short/-220020068_456249259/\n",
            "  inflating: data_test_short/-220020068_456249259/-220020068_456249259.mp4  \n",
            "   creating: data_test_short/-220020068_456255389/\n",
            "  inflating: data_test_short/-220020068_456255389/-220020068_456255389.mp4  \n",
            "   creating: data_test_short/-220020068_456249720/\n",
            "  inflating: data_test_short/-220020068_456249720/-220020068_456249720.mp4  \n",
            "   creating: data_test_short/-220020068_456249272/\n",
            "  inflating: data_test_short/-220020068_456249272/-220020068_456249272.mp4  \n",
            "   creating: data_test_short/-220020068_456249318/\n",
            "  inflating: data_test_short/-220020068_456249318/-220020068_456249318.mp4  \n",
            "   creating: data_test_short/-220020068_456249222/\n",
            "  inflating: data_test_short/-220020068_456249222/-220020068_456249222.mp4  \n",
            "   creating: data_test_short/-220020068_456249358/\n",
            "  inflating: data_test_short/-220020068_456249358/-220020068_456249358.mp4  \n",
            "   creating: data_test_short/-220020068_456249204/\n",
            "  inflating: data_test_short/-220020068_456249204/-220020068_456249204.mp4  \n",
            "   creating: data_test_short/-220020068_456249309/\n",
            "  inflating: data_test_short/-220020068_456249309/-220020068_456249309.mp4  \n",
            "   creating: data_test_short/-220020068_456255346/\n",
            "  inflating: data_test_short/-220020068_456255346/-220020068_456255346.mp4  \n",
            "   creating: data_test_short/-220020068_456249214/\n",
            "  inflating: data_test_short/-220020068_456249214/-220020068_456249214.mp4  \n",
            "   creating: data_test_short/-220020068_456249275/\n",
            "  inflating: data_test_short/-220020068_456249275/-220020068_456249275.mp4  \n",
            "   creating: data_test_short/-220020068_456255393/\n",
            "  inflating: data_test_short/-220020068_456255393/-220020068_456255393.mp4  \n",
            "   creating: data_test_short/-220020068_456249208/\n",
            "  inflating: data_test_short/-220020068_456249208/-220020068_456249208.mp4  \n",
            "   creating: data_test_short/-220020068_456249368/\n",
            "  inflating: data_test_short/-220020068_456249368/-220020068_456249368.mp4  \n",
            "   creating: data_test_short/-220020068_456257137/\n",
            "  inflating: data_test_short/-220020068_456257137/-220020068_456257137.mp4  \n",
            "   creating: data_test_short/-220020068_456249216/\n",
            "  inflating: data_test_short/-220020068_456249216/-220020068_456249216.mp4  \n",
            "   creating: data_test_short/-220020068_456249350/\n",
            "  inflating: data_test_short/-220020068_456249350/-220020068_456249350.mp4  \n",
            "   creating: data_test_short/-220020068_456255410/\n",
            "  inflating: data_test_short/-220020068_456255410/-220020068_456255410.mp4  \n",
            "   creating: data_test_short/-220020068_456249313/\n",
            "  inflating: data_test_short/-220020068_456249313/-220020068_456249313.mp4  \n",
            "   creating: data_test_short/-220020068_456255411/\n",
            "  inflating: data_test_short/-220020068_456255411/-220020068_456255411.mp4  \n",
            "   creating: data_test_short/-220020068_456249211/\n",
            "  inflating: data_test_short/-220020068_456249211/-220020068_456249211.mp4  \n",
            "   creating: data_test_short/-220020068_456249352/\n",
            "  inflating: data_test_short/-220020068_456249352/-220020068_456249352.mp4  \n",
            "   creating: data_test_short/-220020068_456249219/\n",
            "  inflating: data_test_short/-220020068_456249219/-220020068_456249219.mp4  \n",
            "   creating: data_test_short/-220020068_456249315/\n",
            "  inflating: data_test_short/-220020068_456249315/-220020068_456249315.mp4  \n",
            "   creating: data_test_short/-220020068_456249692/\n",
            "  inflating: data_test_short/-220020068_456249692/-220020068_456249692.mp4  \n",
            "   creating: data_test_short/-220020068_456255338/\n",
            "  inflating: data_test_short/-220020068_456255338/-220020068_456255338.mp4  \n",
            "   creating: data_test_short/-220020068_456255399/\n",
            "  inflating: data_test_short/-220020068_456255399/-220020068_456255399.mp4  \n",
            "   creating: data_test_short/-220020068_456249233/\n",
            "  inflating: data_test_short/-220020068_456249233/-220020068_456249233.mp4  \n",
            "  inflating: data_test_short/labels.json  \n",
            "--2025-06-17 14:33:55--  https://downloader.disk.yandex.ru/disk/1e67f4cae27549881cbe71b969b1e3bceebc3b7e6aea1c5d3cb3af6601ccf641/6851b512/hHsHnWApe_ASqMVFpLHBF8Unvfzm5Nl_X4JrfVLIuvqJzvXq6WpV4kEFZ7076ChtuPRZ3YnMw52g7A5L4wtjpg%3D%3D?uid=0&filename=data_train_short.zip&disposition=attachment&hash=CiUP2GVabcJrdEtanXrBznHj3OASP4ZvhoPAodSkVWZ5gOXMbkv88GPVjE7EiZSWq/J6bpmRyOJonT3VoXnDag%3D%3D%3A&limit=0&content_type=application%2Fzip&owner_uid=176861886&fsize=19987339290&hid=5979f7f50fc5e10e0c0c51358ee33d88&media_type=compressed&tknv=v3\n",
            "Resolving downloader.disk.yandex.ru (downloader.disk.yandex.ru)... 77.88.21.127, 2a02:6b8::2:127\n",
            "Connecting to downloader.disk.yandex.ru (downloader.disk.yandex.ru)|77.88.21.127|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://s216klg.storage.yandex.net/rdisk/1e67f4cae27549881cbe71b969b1e3bceebc3b7e6aea1c5d3cb3af6601ccf641/6851b512/hHsHnWApe_ASqMVFpLHBF8Unvfzm5Nl_X4JrfVLIuvqJzvXq6WpV4kEFZ7076ChtuPRZ3YnMw52g7A5L4wtjpg==?uid=0&filename=data_train_short.zip&disposition=attachment&hash=CiUP2GVabcJrdEtanXrBznHj3OASP4ZvhoPAodSkVWZ5gOXMbkv88GPVjE7EiZSWq/J6bpmRyOJonT3VoXnDag%3D%3D%3A&limit=0&content_type=application%2Fzip&owner_uid=176861886&fsize=19987339290&hid=5979f7f50fc5e10e0c0c51358ee33d88&media_type=compressed&tknv=v3&ts=637c8c129e880&s=1cd7bbeb43dd5c3f3b56b61642c79433de32b0cf59a1102951526fe10a8a5413&pb=U2FsdGVkX18dp5ddlmvNvYcXDq05tGORRNVK7QpoSW5RBUAxqF5xJr9rJx4_smm-D7-24Fdlqhx5b2iamj0syWiKxoW1m_7h2Hv9ef3M1QI [following]\n",
            "--2025-06-17 14:33:56--  https://s216klg.storage.yandex.net/rdisk/1e67f4cae27549881cbe71b969b1e3bceebc3b7e6aea1c5d3cb3af6601ccf641/6851b512/hHsHnWApe_ASqMVFpLHBF8Unvfzm5Nl_X4JrfVLIuvqJzvXq6WpV4kEFZ7076ChtuPRZ3YnMw52g7A5L4wtjpg==?uid=0&filename=data_train_short.zip&disposition=attachment&hash=CiUP2GVabcJrdEtanXrBznHj3OASP4ZvhoPAodSkVWZ5gOXMbkv88GPVjE7EiZSWq/J6bpmRyOJonT3VoXnDag%3D%3D%3A&limit=0&content_type=application%2Fzip&owner_uid=176861886&fsize=19987339290&hid=5979f7f50fc5e10e0c0c51358ee33d88&media_type=compressed&tknv=v3&ts=637c8c129e880&s=1cd7bbeb43dd5c3f3b56b61642c79433de32b0cf59a1102951526fe10a8a5413&pb=U2FsdGVkX18dp5ddlmvNvYcXDq05tGORRNVK7QpoSW5RBUAxqF5xJr9rJx4_smm-D7-24Fdlqhx5b2iamj0syWiKxoW1m_7h2Hv9ef3M1QI\n",
            "Resolving s216klg.storage.yandex.net (s216klg.storage.yandex.net)... 5.255.221.216, 2a02:6b8:c41:25a:0:41af:efcf:816f\n",
            "Connecting to s216klg.storage.yandex.net (s216klg.storage.yandex.net)|5.255.221.216|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 19987339290 (19G) [application/zip]\n",
            "Saving to: ‘dataset.zip’\n",
            "\n",
            "dataset.zip         100%[===================>]  18.61G  21.4MB/s    in 14m 56s \n",
            "\n",
            "2025-06-17 14:48:54 (21.3 MB/s) - ‘dataset.zip’ saved [19987339290/19987339290]\n",
            "\n",
            "Archive:  dataset.zip\n",
            "   creating: data_train_short/\n",
            "   creating: data_train_short/-220020068_456255414/\n",
            "  inflating: data_train_short/-220020068_456255414/-220020068_456255414.mp4  \n",
            "   creating: data_train_short/-220020068_456249693/\n",
            "  inflating: data_train_short/-220020068_456249693/-220020068_456249693.mp4  \n",
            "   creating: data_train_short/-220020068_456255339/\n",
            "  inflating: data_train_short/-220020068_456255339/-220020068_456255339.mp4  \n",
            "   creating: data_train_short/-220020068_456241755/\n",
            "  inflating: data_train_short/-220020068_456241755/-220020068_456241755.mp4  \n",
            "   creating: data_train_short/-220020068_456241671/\n",
            "  inflating: data_train_short/-220020068_456241671/-220020068_456241671.mp4  \n",
            "   creating: data_train_short/-220020068_456255340/\n",
            "  inflating: data_train_short/-220020068_456255340/-220020068_456255340.mp4  \n",
            "   creating: data_train_short/-220020068_456241756/\n",
            "  inflating: data_train_short/-220020068_456241756/-220020068_456241756.mp4  \n",
            "   creating: data_train_short/-220020068_456256016/\n",
            "  inflating: data_train_short/-220020068_456256016/-220020068_456256016.mp4  \n",
            "   creating: data_train_short/-220020068_456249732/\n",
            "  inflating: data_train_short/-220020068_456249732/-220020068_456249732.mp4  \n",
            "   creating: data_train_short/-220020068_456255332/\n",
            "  inflating: data_train_short/-220020068_456255332/-220020068_456255332.mp4  \n",
            "   creating: data_train_short/-220020068_456241672/\n",
            "  inflating: data_train_short/-220020068_456241672/-220020068_456241672.mp4  \n",
            "   creating: data_train_short/-220020068_456255341/\n",
            "  inflating: data_train_short/-220020068_456255341/-220020068_456255341.mp4  \n",
            "   creating: data_train_short/-220020068_456256475/\n",
            "  inflating: data_train_short/-220020068_456256475/-220020068_456256475.mp4  \n",
            "   creating: data_train_short/-220020068_456256013/\n",
            "  inflating: data_train_short/-220020068_456256013/-220020068_456256013.mp4  \n",
            "   creating: data_train_short/-220020068_456248657/\n",
            "  inflating: data_train_short/-220020068_456248657/-220020068_456248657.mp4  \n",
            "   creating: data_train_short/-220020068_456241673/\n",
            "  inflating: data_train_short/-220020068_456241673/-220020068_456241673.mp4  \n",
            "   creating: data_train_short/-220020068_456255402/\n",
            "  inflating: data_train_short/-220020068_456255402/-220020068_456255402.mp4  \n",
            "   creating: data_train_short/-220020068_456257139/\n",
            "  inflating: data_train_short/-220020068_456257139/-220020068_456257139.mp4  \n",
            "   creating: data_train_short/-220020068_456254621/\n",
            "  inflating: data_train_short/-220020068_456254621/-220020068_456254621.mp4  \n",
            "   creating: data_train_short/-220020068_456241758/\n",
            "  inflating: data_train_short/-220020068_456241758/-220020068_456241758.mp4  \n",
            "   creating: data_train_short/-220020068_456252055/\n",
            "  inflating: data_train_short/-220020068_456252055/-220020068_456252055.mp4  \n",
            "   creating: data_train_short/-220020068_456249739/\n",
            "  inflating: data_train_short/-220020068_456249739/-220020068_456249739.mp4  \n",
            "   creating: data_train_short/-220020068_456255403/\n",
            "  inflating: data_train_short/-220020068_456255403/-220020068_456255403.mp4  \n",
            "   creating: data_train_short/-220020068_456256012/\n",
            "  inflating: data_train_short/-220020068_456256012/-220020068_456256012.mp4  \n",
            "   creating: data_train_short/-220020068_456249716/\n",
            "  inflating: data_train_short/-220020068_456249716/-220020068_456249716.mp4  \n",
            "   creating: data_train_short/-220020068_456255389/\n",
            "  inflating: data_train_short/-220020068_456255389/-220020068_456255389.mp4  \n",
            "   creating: data_train_short/-220020068_456257141/\n",
            "  inflating: data_train_short/-220020068_456257141/-220020068_456257141.mp4  \n",
            "   creating: data_train_short/-220020068_456241851/\n",
            "  inflating: data_train_short/-220020068_456241851/-220020068_456241851.mp4  \n",
            "   creating: data_train_short/-220020068_456256571/\n",
            "  inflating: data_train_short/-220020068_456256571/-220020068_456256571.mp4  \n",
            "   creating: data_train_short/-220020068_456256019/\n",
            "  inflating: data_train_short/-220020068_456256019/-220020068_456256019.mp4  \n",
            "   creating: data_train_short/-220020068_456249720/\n",
            "  inflating: data_train_short/-220020068_456249720/-220020068_456249720.mp4  \n",
            "   creating: data_train_short/-220020068_456255344/\n",
            "  inflating: data_train_short/-220020068_456255344/-220020068_456255344.mp4  \n",
            "   creating: data_train_short/-220020068_456255405/\n",
            "  inflating: data_train_short/-220020068_456255405/-220020068_456255405.mp4  \n",
            "   creating: data_train_short/-220020068_456255391/\n",
            "  inflating: data_train_short/-220020068_456255391/-220020068_456255391.mp4  \n",
            "   creating: data_train_short/-220020068_456241844/\n",
            "  inflating: data_train_short/-220020068_456241844/-220020068_456241844.mp4  \n",
            "   creating: data_train_short/-220020068_456254282/\n",
            "  inflating: data_train_short/-220020068_456254282/-220020068_456254282.mp4  \n",
            "   creating: data_train_short/-220020068_456239859/\n",
            "  inflating: data_train_short/-220020068_456239859/-220020068_456239859.mp4  \n",
            "   creating: data_train_short/-220020068_456255346/\n",
            "  inflating: data_train_short/-220020068_456255346/-220020068_456255346.mp4  \n",
            "   creating: data_train_short/-220020068_456255392/\n",
            "  inflating: data_train_short/-220020068_456255392/-220020068_456255392.mp4  \n",
            "   creating: data_train_short/-220020068_456241845/\n",
            "  inflating: data_train_short/-220020068_456241845/-220020068_456241845.mp4  \n",
            "   creating: data_train_short/-220020068_456255766/\n",
            "  inflating: data_train_short/-220020068_456255766/-220020068_456255766.mp4  \n",
            "   creating: data_train_short/-220020068_456256003/\n",
            "  inflating: data_train_short/-220020068_456256003/-220020068_456256003.mp4  \n",
            "   creating: data_train_short/-220020068_456255393/\n",
            "  inflating: data_train_short/-220020068_456255393/-220020068_456255393.mp4  \n",
            "   creating: data_train_short/-220020068_456257136/\n",
            "  inflating: data_train_short/-220020068_456257136/-220020068_456257136.mp4  \n",
            "   creating: data_train_short/-220020068_456241846/\n",
            "  inflating: data_train_short/-220020068_456241846/-220020068_456241846.mp4  \n",
            "   creating: data_train_short/-220020068_456255767/\n",
            "  inflating: data_train_short/-220020068_456255767/-220020068_456255767.mp4  \n",
            "   creating: data_train_short/-220020068_456254537/\n",
            "  inflating: data_train_short/-220020068_456254537/-220020068_456254537.mp4  \n",
            "   creating: data_train_short/-220020068_456255394/\n",
            "  inflating: data_train_short/-220020068_456255394/-220020068_456255394.mp4  \n",
            "   creating: data_train_short/-220020068_456255409/\n",
            "  inflating: data_train_short/-220020068_456255409/-220020068_456255409.mp4  \n",
            "   creating: data_train_short/-220020068_456257137/\n",
            "  inflating: data_train_short/-220020068_456257137/-220020068_456257137.mp4  \n",
            "   creating: data_train_short/-220020068_456241847/\n",
            "  inflating: data_train_short/-220020068_456241847/-220020068_456241847.mp4  \n",
            "   creating: data_train_short/-220020068_456255773/\n",
            "  inflating: data_train_short/-220020068_456255773/-220020068_456255773.mp4  \n",
            "   creating: data_train_short/-220020068_456256005/\n",
            "  inflating: data_train_short/-220020068_456256005/-220020068_456256005.mp4  \n",
            "   creating: data_train_short/-220020068_456256868/\n",
            "  inflating: data_train_short/-220020068_456256868/-220020068_456256868.mp4  \n",
            "   creating: data_train_short/-220020068_456255349/\n",
            "  inflating: data_train_short/-220020068_456255349/-220020068_456255349.mp4  \n",
            "   creating: data_train_short/-220020068_456255395/\n",
            "  inflating: data_train_short/-220020068_456255395/-220020068_456255395.mp4  \n",
            "   creating: data_train_short/-220020068_456255410/\n",
            "  inflating: data_train_short/-220020068_456255410/-220020068_456255410.mp4  \n",
            "   creating: data_train_short/-220020068_456255779/\n",
            "  inflating: data_train_short/-220020068_456255779/-220020068_456255779.mp4  \n",
            "   creating: data_train_short/-220020068_456256893/\n",
            "  inflating: data_train_short/-220020068_456256893/-220020068_456256893.mp4  \n",
            "   creating: data_train_short/-220020068_456241682/\n",
            "  inflating: data_train_short/-220020068_456241682/-220020068_456241682.mp4  \n",
            "   creating: data_train_short/-220020068_456255396/\n",
            "  inflating: data_train_short/-220020068_456255396/-220020068_456255396.mp4  \n",
            "   creating: data_train_short/-220020068_456255411/\n",
            "  inflating: data_train_short/-220020068_456255411/-220020068_456255411.mp4  \n",
            "   creating: data_train_short/-220020068_456254614/\n",
            "  inflating: data_train_short/-220020068_456254614/-220020068_456254614.mp4  \n",
            "   creating: data_train_short/-220020068_456241849/\n",
            "  inflating: data_train_short/-220020068_456241849/-220020068_456241849.mp4  \n",
            "   creating: data_train_short/-220020068_456255780/\n",
            "  inflating: data_train_short/-220020068_456255780/-220020068_456255780.mp4  \n",
            "   creating: data_train_short/-220020068_456249667/\n",
            "  inflating: data_train_short/-220020068_456249667/-220020068_456249667.mp4  \n",
            "   creating: data_train_short/-220020068_456253855/\n",
            "  inflating: data_train_short/-220020068_456253855/-220020068_456253855.mp4  \n",
            "   creating: data_train_short/-220020068_456255412/\n",
            "  inflating: data_train_short/-220020068_456255412/-220020068_456255412.mp4  \n",
            "   creating: data_train_short/-220020068_456241850/\n",
            "  inflating: data_train_short/-220020068_456241850/-220020068_456241850.mp4  \n",
            "   creating: data_train_short/-220020068_456253876/\n",
            "  inflating: data_train_short/-220020068_456253876/-220020068_456253876.mp4  \n",
            "   creating: data_train_short/-220020068_456256430/\n",
            "  inflating: data_train_short/-220020068_456256430/-220020068_456256430.mp4  \n",
            "   creating: data_train_short/-220020068_456249692/\n",
            "  inflating: data_train_short/-220020068_456249692/-220020068_456249692.mp4  \n",
            "   creating: data_train_short/-220020068_456255338/\n",
            "  inflating: data_train_short/-220020068_456255338/-220020068_456255338.mp4  \n",
            "   creating: data_train_short/-220020068_456255407/\n",
            "  inflating: data_train_short/-220020068_456255407/-220020068_456255407.mp4  \n",
            "   creating: data_train_short/-220020068_456255399/\n",
            "  inflating: data_train_short/-220020068_456255399/-220020068_456255399.mp4  \n",
            "   creating: data_train_short/-220020068_456249719/\n",
            "  inflating: data_train_short/-220020068_456249719/-220020068_456249719.mp4  \n",
            "   creating: data_train_short/-220020068_456255400/\n",
            "  inflating: data_train_short/-220020068_456255400/-220020068_456255400.mp4  \n",
            "   creating: data_train_short/-220020068_456256446/\n",
            "  inflating: data_train_short/-220020068_456256446/-220020068_456256446.mp4  \n",
            "   creating: data_train_short/-220020068_456255401/\n",
            "  inflating: data_train_short/-220020068_456255401/-220020068_456255401.mp4  \n",
            "   creating: data_train_short/-220020068_456249733/\n",
            "  inflating: data_train_short/-220020068_456249733/-220020068_456249733.mp4  \n",
            "  inflating: data_train_short/labels.json  \n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "\n",
        "yandex_url_test = \"https://disk.yandex.ru/d/lgAOpG2O1VAs5w\"\n",
        "yandex_url_train = \"https://disk.yandex.ru/d/bg0Gtr4bFnHJDQ\"\n",
        "\n",
        "for j in [yandex_url_test, yandex_url_train]:\n",
        "    download_url = f\"https://cloud-api.yandex.net/v1/disk/public/resources/download?public_key={j}\"\n",
        "\n",
        "    response = requests.get(download_url)\n",
        "    if response.status_code == 200:\n",
        "        direct_url = response.json()[\"href\"]\n",
        "        !wget -O dataset.zip \"{direct_url}\"\n",
        "        !unzip dataset.zip\n",
        "    else:\n",
        "        print(\"Ошибка:\", response.status_code)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm dataset.zip"
      ],
      "metadata": {
        "id": "sZnSjWZ7B0j3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision.transforms as T\n",
        "import torchvision.models as models\n",
        "\n",
        "import cv2\n",
        "import librosa\n",
        "import soundfile as sf\n",
        "import glob\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "_m1443lBObNP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n"
      ],
      "metadata": {
        "id": "Mzt9bgqFH9gP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Гиперпараметры"
      ],
      "metadata": {
        "id": "o-_FIKWFsHEp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Train и test намеренно перемешаны из-за объёма данных рассматриваемых видео\n",
        "TEST_LABELS_JSON = '/content/data_train_short/labels.json'\n",
        "TRAIN_LABELS_JSON = '/content/data_test_short/labels.json'\n",
        "TEST_DIR = '/content/data_train_short'\n",
        "TRAIN_DIR = '/content/data_test_short'\n",
        "\n",
        "BATCH_SIZE = 4\n",
        "NUM_EPOCHS = 20\n",
        "\n",
        "SEQ_LEN = 30\n",
        "FPS = 1\n",
        "AUDIO_SAMPLE_RATE = 16000\n",
        "\n",
        "LEARNING_RATE = 0.0005\n",
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "vWZbQu2VCOZj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(DEVICE)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q3Ap68D8Cks6",
        "outputId": "a0f1d9ef-623d-4e30-d8ba-b3ae5d5fc7f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Перевод времени в секунды"
      ],
      "metadata": {
        "id": "1V5Js3yAsKS1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def to_seconds(timestr):\n",
        "    parts = list(map(int, timestr.split(':')))\n",
        "    if len(parts) == 3:\n",
        "        h, m, s = parts\n",
        "        return h * 3600 + m * 60 + s\n",
        "    elif len(parts) == 2:\n",
        "        m, s = parts\n",
        "        return m * 60 + s\n",
        "    else:\n",
        "        return parts[0]\n",
        "\n",
        "def seconds_to_time(secs):\n",
        "    return f\"{secs//3600:02}:{(secs%3600)//60:02}:{secs%60:02}\""
      ],
      "metadata": {
        "id": "udDPI9CRCmdI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class IntroDataset(Dataset):\n",
        "    def __init__(self, root_dir, labels_json, seq_len=SEQ_LEN, fps=FPS, train=False):\n",
        "        self.MAX_DURATION = 40 #Максимальное время заставок, которые мы рассматриваем. Также ставится как предел для обрезания видео.\n",
        "        self.root_dir = root_dir\n",
        "        self.seq_len = seq_len\n",
        "        self.fps = fps\n",
        "        self.train = train\n",
        "\n",
        "        with open(labels_json, 'r', encoding='utf-8') as f:\n",
        "            all_labels = json.load(f)\n",
        "\n",
        "        self.labels = {}\n",
        "        for video_id, label in all_labels.items():\n",
        "            try:\n",
        "                end_gt = to_seconds(label['end'])\n",
        "                start_gt = to_seconds(label['start'])\n",
        "                if 0 < end_gt <= self.MAX_DURATION and start_gt < end_gt:\n",
        "                    self.labels[video_id] = {\n",
        "                        'start': start_gt,\n",
        "                        'end': end_gt\n",
        "                    }\n",
        "            except:\n",
        "                continue\n",
        "\n",
        "        self.video_ids = list(self.labels.keys())\n",
        "\n",
        "        # Аугментации только для обучения\n",
        "        self.transform = T.Compose([\n",
        "            T.ToPILImage(),\n",
        "            T.Resize((224, 224)),\n",
        "            T.RandomHorizontalFlip() if train else T.Lambda(lambda x: x),\n",
        "            T.ColorJitter(brightness=0.2, contrast=0.2) if train else T.Lambda(lambda x: x),\n",
        "            T.ToTensor(),\n",
        "            T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "        ])\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.video_ids)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        vid = self.video_ids[idx]\n",
        "        info = self.labels[vid]\n",
        "        start_gt = info['start']\n",
        "        end_gt = info['end']\n",
        "\n",
        "        # Случайный сдвиг для набора train\n",
        "        if self.train:\n",
        "            max_start = max(0, min(start_gt, self.MAX_DURATION - self.seq_len - 5))\n",
        "            start_s = np.random.randint(0, max_start + 1) if max_start > 0 else 0\n",
        "        else:\n",
        "            start_s = max(0, start_gt - np.random.randint(0, 5))\n",
        "\n",
        "        video_folder = os.path.join(self.root_dir, vid)\n",
        "        mp4_path = glob.glob(os.path.join(video_folder, \"*.mp4\"))[0]\n",
        "\n",
        "        # Извлечение кадров\n",
        "        cap = cv2.VideoCapture(mp4_path)\n",
        "        fps_video = cap.get(cv2.CAP_PROP_FPS) or 25\n",
        "        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "\n",
        "        frames = []\n",
        "        for i in range(self.seq_len):\n",
        "            frame_pos = int((start_s + i) * fps_video)\n",
        "            if frame_pos >= total_frames:\n",
        "                frames.append(torch.zeros(3, 224, 224))\n",
        "                continue\n",
        "\n",
        "            cap.set(cv2.CAP_PROP_POS_FRAMES, frame_pos)\n",
        "            ret, frame = cap.read()\n",
        "            if ret:\n",
        "                frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "                frames.append(self.transform(frame))\n",
        "            else:\n",
        "                frames.append(torch.zeros(3, 224, 224))\n",
        "        cap.release()\n",
        "\n",
        "        video_feats = torch.stack(frames)\n",
        "\n",
        "        # Извлечение аудио\n",
        "        try:\n",
        "            y, sr = librosa.load(mp4_path, sr=AUDIO_SAMPLE_RATE, duration=self.MAX_DURATION)\n",
        "            audio_feats = []\n",
        "            for i in range(self.seq_len):\n",
        "                start_sample = int((start_s + i) * AUDIO_SAMPLE_RATE)\n",
        "                end_sample = int((start_s + i + 1) * AUDIO_SAMPLE_RATE)\n",
        "                segment = y[start_sample:end_sample]\n",
        "                audio_feats.append(np.mean(np.abs(segment))) if segment.any() else 0.0\n",
        "        except:\n",
        "            audio_feats = [0.0] * self.seq_len\n",
        "\n",
        "        while len(audio_feats) < self.seq_len:\n",
        "            audio_feats.append(0.0)\n",
        "\n",
        "        audio_feats = torch.tensor(audio_feats, dtype=torch.float32).unsqueeze(1)\n",
        "\n",
        "        # Нормализованные метки временных отрезков\n",
        "        start_rel = max(0, (start_gt - start_s) / self.seq_len)\n",
        "        end_rel = min(1, (end_gt - start_s) / self.seq_len)\n",
        "\n",
        "        return video_feats, audio_feats, torch.tensor([start_rel, end_rel]), vid\n"
      ],
      "metadata": {
        "id": "leEXuEYlCqZu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yZ0BSN45m3lF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "I6DKvaKIOQzk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UdOYsz0dOSX5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Модель сети"
      ],
      "metadata": {
        "id": "ZEfMYnR9tApl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class IntroDetector(nn.Module):\n",
        "    def __init__(self, video_dim=512, audio_dim=1, hidden_size=128):\n",
        "        super().__init__()\n",
        "        self.cnn = models.resnet18(pretrained=True)\n",
        "        self.cnn.fc = nn.Identity()\n",
        "\n",
        "        self.lstm = nn.LSTM(\n",
        "            input_size=video_dim + audio_dim,\n",
        "            hidden_size=hidden_size,\n",
        "            num_layers=2,\n",
        "            batch_first=True,\n",
        "            bidirectional=True\n",
        "        )\n",
        "\n",
        "        self.regressor = nn.Sequential(\n",
        "            nn.Linear(hidden_size * 2, hidden_size),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_size, 2),\n",
        "            nn.Sigmoid()  # Нормализация выхода [0, 1]\n",
        "        )\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(hidden_size * 2, 1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, video, audio):\n",
        "        B, seq, C, H, W = video.size()\n",
        "        v = video.view(B * seq, C, H, W)\n",
        "        video_feats = self.cnn(v).view(B, seq, -1)\n",
        "\n",
        "        # Конкатенация признаков\n",
        "        x = torch.cat([video_feats, audio], dim=2)\n",
        "\n",
        "        # Обработка последовательности\n",
        "        lstm_out, _ = self.lstm(x)\n",
        "        last_out = lstm_out[:, -1, :]\n",
        "\n",
        "        # Регрессия временных меток\n",
        "        time_output = self.regressor(last_out)\n",
        "\n",
        "        # Классификация наличия заставки\n",
        "        presence_output = self.classifier(last_out)\n",
        "\n",
        "        return time_output, presence_output"
      ],
      "metadata": {
        "id": "2ZiNYZQjCrQa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_epoch(model, loader, optimizer, criterion_reg, criterion_cls):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for v, a, y, _ in tqdm(loader, desc=\"Training\"):\n",
        "        v, a, y = v.to(DEVICE), a.to(DEVICE), y.float().to(DEVICE)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        time_pred, presence_pred = model(v, a)\n",
        "\n",
        "        # Multi-task loss\n",
        "        loss_reg = criterion_reg(time_pred, y)\n",
        "        loss_cls = criterion_cls(presence_pred, (y.mean(dim=1) > 0).float().view(-1, 1))\n",
        "        loss = 0.7 * loss_reg + 0.3 * loss_cls\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    return total_loss / len(loader)"
      ],
      "metadata": {
        "id": "GCXokWVKCtAr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def eval_epoch(model, loader, criterion_reg, criterion_cls):\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    reg_errors = []\n",
        "    cls_correct = 0\n",
        "    total_samples = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for v, a, y, _ in tqdm(loader, desc=\"Evaluating\"):\n",
        "            v, a, y = v.to(DEVICE), a.to(DEVICE), y.float().to(DEVICE)\n",
        "\n",
        "            time_pred, presence_pred = model(v, a)\n",
        "\n",
        "            loss_reg = criterion_reg(time_pred, y)\n",
        "            loss_cls = criterion_cls(presence_pred, (y.mean(dim=1) > 0).float().view(-1, 1))\n",
        "            loss = 0.7 * loss_reg + 0.3 * loss_cls\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            abs_errors = torch.abs(time_pred - y).mean(dim=0)\n",
        "            reg_errors.append(abs_errors.cpu())\n",
        "\n",
        "            cls_pred = (presence_pred > 0.5).float()\n",
        "            cls_target = (y.mean(dim=1) > 0).float().view(-1, 1)\n",
        "            cls_correct += (cls_pred == cls_target).sum().item()\n",
        "            total_samples += v.size(0)\n",
        "\n",
        "    avg_reg_error = torch.stack(reg_errors).mean(dim=0)\n",
        "    cls_accuracy = cls_correct / total_samples\n",
        "\n",
        "    return total_loss / len(loader), avg_reg_error, cls_accuracy"
      ],
      "metadata": {
        "id": "afis7f7lCvHf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def custom_collate(batch):\n",
        "    \"\"\"\n",
        "    batch: (video_feats, audio_feats, tensor([start_rel, end_rel]), vid)\n",
        "    \"\"\"\n",
        "\n",
        "    video_feats, audio_feats, rels, vids = zip(*batch)\n",
        "\n",
        "    # Паддинг видео\n",
        "    max_video_len = max(v.shape[0] for v in video_feats)\n",
        "    padded_videos = []\n",
        "    for v in video_feats:\n",
        "        pad_len = max_video_len - v.shape[0]\n",
        "        if pad_len > 0:\n",
        "            pad = torch.zeros(pad_len, *v.shape[1:], dtype=v.dtype)\n",
        "            v = torch.cat([v, pad], dim=0)\n",
        "        padded_videos.append(v)\n",
        "    videos = torch.stack(padded_videos)  # (B, T_max, 3, 224, 224)\n",
        "\n",
        "    # Паддинг аудио\n",
        "    max_audio_len = max(a.shape[0] for a in audio_feats)\n",
        "    padded_audios = []\n",
        "    for a in audio_feats:\n",
        "        pad_len = max_audio_len - a.shape[0]\n",
        "        if pad_len > 0:\n",
        "            pad = torch.zeros(pad_len, *a.shape[1:], dtype=a.dtype)\n",
        "            a = torch.cat([a, pad], dim=0)\n",
        "        padded_audios.append(a)\n",
        "    audios = torch.stack(padded_audios)  # (B, T_max, audio_len)\n",
        "\n",
        "    rels_tensor = torch.stack(rels)  # (B, 2)\n",
        "\n",
        "    return videos, audios, rels_tensor, list(vids)"
      ],
      "metadata": {
        "id": "d_Wqo58eCxgr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4PnSgoCZITKN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = IntroDataset(TRAIN_DIR, TRAIN_LABELS_JSON, train=True)\n",
        "test_dataset = IntroDataset(TEST_DIR, TEST_LABELS_JSON, train=False)\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    collate_fn=custom_collate,\n",
        "    shuffle=True,\n",
        "    num_workers=0,\n",
        "    pin_memory=True\n",
        ")\n",
        "test_loader = DataLoader(\n",
        "    test_dataset,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    collate_fn=custom_collate,\n",
        "    shuffle=False,\n",
        "    num_workers=0\n",
        ")"
      ],
      "metadata": {
        "id": "h9DJRFGoIaeM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = IntroDetector().to(DEVICE)\n",
        "optimizer = optim.AdamW(model.parameters(), lr=LEARNING_RATE, weight_decay=1e-4)\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=3, factor=0.5)"
      ],
      "metadata": {
        "id": "ZhDT1SKUC2R6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a8eb770-a195-4301-aacd-f2b89e37d9d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
            "100%|██████████| 44.7M/44.7M [00:00<00:00, 195MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "criterion_reg = nn.HuberLoss()\n",
        "criterion_cls = nn.BCEWithLogitsLoss()"
      ],
      "metadata": {
        "id": "R5oA8YgGDGem"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_time(model, video_tensor, audio_tensor):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        time_pred, presence = model(video_tensor.unsqueeze(0), audio_tensor.unsqueeze(0))\n",
        "        if presence.item() > 0.5:\n",
        "            return time_pred.squeeze().cpu().numpy()\n",
        "        return None"
      ],
      "metadata": {
        "id": "7MCTOSOGCZyb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_loss = float('inf')\n",
        "for epoch in range(1, NUM_EPOCHS + 1):\n",
        "    # Обучение\n",
        "    model.train()\n",
        "    train_loss = train_epoch(model, train_loader, optimizer, criterion_reg, criterion_cls)\n",
        "\n",
        "    # Валидация\n",
        "    val_loss, val_reg_err, val_cls_acc = eval_epoch(model, test_loader, criterion_reg, criterion_cls)\n",
        "\n",
        "    # Логирование\n",
        "    print(f\"\\nEpoch {epoch}/{NUM_EPOCHS}\")\n",
        "    print(f\"Train Loss: {train_loss:.4f}\")\n",
        "    print(f\"Val Loss: {val_loss:.4f}\")\n",
        "    print(f\"Val Reg Errors - Start: {val_reg_err[0]:.3f}, Duration: {val_reg_err[1]:.3f}\")\n",
        "    print(f\"Val Cls Acc: {val_cls_acc:.4f}\")\n",
        "\n",
        "    scheduler.step(val_loss)\n",
        "\n",
        "    if val_loss < best_loss:\n",
        "        best_loss = val_loss\n",
        "        torch.save(model.state_dict(), 'best_model.pth')\n",
        "        print(\"Saved best model!\")\n",
        "\n",
        "    # Ранняя остановка\n",
        "    if epoch > 10 and val_loss > best_loss * 1.1:\n",
        "        print(\"Early stopping triggered\")\n",
        "        break\n",
        "\n",
        "model.load_state_dict(torch.load('best_model.pth'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "-zVEHtsJC7bd",
        "outputId": "db35e0c6-ad92-49a3-fb70-c7e5ccbdf60a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 9/9 [02:32<00:00, 16.93s/it]\n",
            "Evaluating: 100%|██████████| 6/6 [01:01<00:00, 10.17s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1/20\n",
            "Train Loss: 0.1332\n",
            "Val Loss: 0.1139\n",
            "Val Reg Errors - Start: 0.137, Duration: 0.205\n",
            "Val Cls Acc: 1.0000\n",
            "Saved best model!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 9/9 [02:14<00:00, 14.95s/it]\n",
            "Evaluating: 100%|██████████| 6/6 [01:00<00:00, 10.16s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 2/20\n",
            "Train Loss: 0.1016\n",
            "Val Loss: 0.1029\n",
            "Val Reg Errors - Start: 0.031, Duration: 0.191\n",
            "Val Cls Acc: 1.0000\n",
            "Saved best model!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 9/9 [02:14<00:00, 14.89s/it]\n",
            "Evaluating: 100%|██████████| 6/6 [01:00<00:00, 10.05s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 3/20\n",
            "Train Loss: 0.0997\n",
            "Val Loss: 0.1027\n",
            "Val Reg Errors - Start: 0.060, Duration: 0.191\n",
            "Val Cls Acc: 1.0000\n",
            "Saved best model!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 9/9 [02:13<00:00, 14.81s/it]\n",
            "Evaluating: 100%|██████████| 6/6 [01:02<00:00, 10.36s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 4/20\n",
            "Train Loss: 0.0987\n",
            "Val Loss: 0.1009\n",
            "Val Reg Errors - Start: 0.050, Duration: 0.167\n",
            "Val Cls Acc: 1.0000\n",
            "Saved best model!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 9/9 [02:14<00:00, 14.93s/it]\n",
            "Evaluating: 100%|██████████| 6/6 [01:00<00:00, 10.12s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 5/20\n",
            "Train Loss: 0.0984\n",
            "Val Loss: 0.1061\n",
            "Val Reg Errors - Start: 0.057, Duration: 0.231\n",
            "Val Cls Acc: 1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 9/9 [02:13<00:00, 14.89s/it]\n",
            "Evaluating: 100%|██████████| 6/6 [01:01<00:00, 10.20s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 6/20\n",
            "Train Loss: 0.0976\n",
            "Val Loss: 0.1025\n",
            "Val Reg Errors - Start: 0.061, Duration: 0.192\n",
            "Val Cls Acc: 1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 9/9 [02:10<00:00, 14.46s/it]\n",
            "Evaluating: 100%|██████████| 6/6 [01:00<00:00, 10.16s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 7/20\n",
            "Train Loss: 0.0978\n",
            "Val Loss: 0.1034\n",
            "Val Reg Errors - Start: 0.060, Duration: 0.198\n",
            "Val Cls Acc: 1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 9/9 [02:12<00:00, 14.73s/it]\n",
            "Evaluating: 100%|██████████| 6/6 [01:01<00:00, 10.19s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 8/20\n",
            "Train Loss: 0.0974\n",
            "Val Loss: 0.1043\n",
            "Val Reg Errors - Start: 0.061, Duration: 0.213\n",
            "Val Cls Acc: 1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 9/9 [02:14<00:00, 14.92s/it]\n",
            "Evaluating: 100%|██████████| 6/6 [01:01<00:00, 10.17s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 9/20\n",
            "Train Loss: 0.0974\n",
            "Val Loss: 0.1041\n",
            "Val Reg Errors - Start: 0.063, Duration: 0.206\n",
            "Val Cls Acc: 1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 9/9 [02:12<00:00, 14.74s/it]\n",
            "Evaluating: 100%|██████████| 6/6 [01:00<00:00, 10.01s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 10/20\n",
            "Train Loss: 0.0985\n",
            "Val Loss: 0.1002\n",
            "Val Reg Errors - Start: 0.040, Duration: 0.170\n",
            "Val Cls Acc: 1.0000\n",
            "Saved best model!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:  11%|█         | 1/9 [00:13<01:48, 13.53s/it]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-732774877>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;31m# Обучение\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion_reg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion_cls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;31m# Валидация\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-10-3889208668>\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m(model, loader, optimizer, criterion_reg, criterion_cls)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mtotal_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Training\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m         \u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1181\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1182\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1183\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    706\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    707\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 708\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    709\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m             if (\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    762\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    763\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 764\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    765\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     50\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     50\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-8-1415137801>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     66\u001b[0m                 \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m             \u001b[0mcap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCAP_PROP_POS_FRAMES\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe_pos\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m             \u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_state_dict(torch.load('best_model.pth'))"
      ],
      "metadata": {
        "id": "tC9yn7eIliMG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc453465-37b7-47b7-a8e0-875e4b1b9eb5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from datetime import timedelta\n",
        "\n",
        "def save_predictions_to_csv(model, dataset, output_file='predictions.csv'):\n",
        "    model.eval()\n",
        "    results = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for idx in tqdm(range(len(dataset)), desc=\"Generating predictions\"):\n",
        "            video, audio, _, video_id = dataset[idx]\n",
        "\n",
        "            # Получаем предсказания\n",
        "            time_pred, presence_prob = model(\n",
        "                video.unsqueeze(0).to(DEVICE),\n",
        "                audio.unsqueeze(0).to(DEVICE)\n",
        "            )\n",
        "\n",
        "            # Конвертируем относительные значения в абсолютные секунды\n",
        "            if presence_prob.item() > 0.5:  # Порог наличия заставки\n",
        "                start_rel, duration_rel = time_pred.squeeze().cpu().numpy()\n",
        "                start_sec = start_rel * dataset.seq_len\n",
        "                end_sec = start_sec + (duration_rel * dataset.seq_len)\n",
        "\n",
        "                # Конвертируем секунды в формат HH:MM:SS\n",
        "                start_time = str(timedelta(seconds=int(start_sec)))\n",
        "                end_time = str(timedelta(seconds=int(end_sec)))\n",
        "            else:\n",
        "                start_time = \"00:00:00\"\n",
        "                end_time = \"00:00:00\"\n",
        "\n",
        "            results.append({\n",
        "                'video_id': video_id,\n",
        "                'start_time': start_time,\n",
        "                'end_time': end_time,\n",
        "                'presence_prob': presence_prob.item()\n",
        "            })\n",
        "\n",
        "    df = pd.DataFrame(results)\n",
        "    df.to_csv(output_file, index=False)\n",
        "    print(f\"Predictions saved to {output_file}\")\n",
        "    return df\n",
        "\n",
        "test_dataset = IntroDataset(TEST_DIR, TEST_LABELS_JSON, train=False)\n",
        "predictions_df = save_predictions_to_csv(model, test_dataset, 'test_predictions.csv')\n",
        "\n",
        "def save_with_ground_truth(model, dataset, output_file='predictions_with_gt.csv'):\n",
        "    model.eval()\n",
        "    results = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for idx in tqdm(range(len(dataset)), desc=\"Generating predictions\"):\n",
        "            video, audio, target, video_id = dataset[idx]\n",
        "\n",
        "            time_pred, presence_prob = model(\n",
        "                video.unsqueeze(0).to(DEVICE),\n",
        "                audio.unsqueeze(0).to(DEVICE)\n",
        "            )\n",
        "\n",
        "            gt_start = target[0].item() * dataset.seq_len\n",
        "            gt_end = gt_start + target[1].item() * dataset.seq_len\n",
        "\n",
        "            if presence_prob.item() > 0.5:\n",
        "                start_rel, duration_rel = time_pred.squeeze().cpu().numpy()\n",
        "                pred_start = start_rel * dataset.seq_len\n",
        "                pred_end = pred_start + duration_rel * dataset.seq_len\n",
        "            else:\n",
        "                pred_start = pred_end = 0\n",
        "\n",
        "            results.append({\n",
        "                'video_id': video_id,\n",
        "                'pred_start': str(timedelta(seconds=int(pred_start))),\n",
        "                'pred_end': str(timedelta(seconds=int(pred_end))),\n",
        "                'gt_start': str(timedelta(seconds=int(gt_start))),\n",
        "                'gt_end': str(timedelta(seconds=int(gt_end))),\n",
        "                'presence_prob': presence_prob.item(),\n",
        "                'error_sec': abs(pred_start - gt_start) + abs(pred_end - gt_end)\n",
        "            })\n",
        "\n",
        "    df = pd.DataFrame(results)\n",
        "    df.to_csv(output_file, index=False)\n",
        "    print(f\"Predictions with GT saved to {output_file}\")\n",
        "    return df\n",
        "\n",
        "full_results_df = save_with_ground_truth(model, test_dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jLw3tbp_RHJO",
        "outputId": "ab63b95f-debb-48da-b340-cb0d59e1ad0d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Generating predictions: 100%|██████████| 21/21 [00:59<00:00,  2.85s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predictions saved to test_predictions.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Generating predictions: 100%|██████████| 21/21 [00:59<00:00,  2.84s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predictions with GT saved to predictions_with_gt.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    }
  ]
}